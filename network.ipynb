{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"network.ipynb","provenance":[{"file_id":"1UdINTuL-f8ClyC4CM7jMpXu6UqX_FtLg","timestamp":1587632153100},{"file_id":"11fDuHnn4Wq0KYK3YTq3SFUf9G8ylkQbM","timestamp":1587579560285}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eNUt_-E7NuX3","colab_type":"text"},"source":["# Training model"]},{"cell_type":"markdown","metadata":{"id":"Xxb9AycWN3lZ","colab_type":"text"},"source":["In this notebook:\n","\n","1.   Data preparation\n","2.   Download Xception model with ImageNet weights\n","3.   Add top layers for binary classification task on top of Xception\n","4.   Short train with Xception layers frozen\n","5.   Long train all layers until best validation loss value found, using early stopping\n","\n"]},{"cell_type":"code","metadata":{"id":"k_WQynGnBlU-","colab_type":"code","outputId":"adeed229-0db8-43e0-c67e-cc3f04ab297c","executionInfo":{"status":"ok","timestamp":1587587410844,"user_tz":-120,"elapsed":2101,"user":{"displayName":"Michał Bernacki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnmPN0hwphGAGXExHQyanC5d6OYykk08Li2O2BHg=s64","userId":"02963925927313730455"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-5Ut-fMb9J_L","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import IPython.display as display\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import os\n","import pathlib"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvEEBg4WJfI2","colab_type":"code","outputId":"731dc541-695f-407f-819c-3a942d829e68","executionInfo":{"status":"ok","timestamp":1587587418523,"user_tz":-120,"elapsed":1829,"user":{"displayName":"Michał Bernacki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnmPN0hwphGAGXExHQyanC5d6OYykk08Li2O2BHg=s64","userId":"02963925927313730455"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Paths to the dataset\n","train_dir = '/content/gdrive/My Drive/dataset/1_train'\n","train_dir = pathlib.Path(train_dir)\n","\n","valid_dir = '/content/gdrive/My Drive/dataset/2_validation'\n","valid_dir = pathlib.Path(valid_dir)\n","\n","#Inspect number of photos in each subset\n","train_count = len(list(train_dir.glob('*/*.png')))\n","valid_count = len(list(valid_dir.glob('*/*.png')))\n","print(\"Number of training photos:\", train_count, \"\\nNumber of validation photos:\", valid_count)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of training photos: 5600 \n","Number of validation photos: 800\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6o5TKfbSSzJO","colab_type":"code","outputId":"61612b0e-b333-459d-eae5-dffeee8ffae6","executionInfo":{"status":"ok","timestamp":1587587420674,"user_tz":-120,"elapsed":550,"user":{"displayName":"Michał Bernacki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnmPN0hwphGAGXExHQyanC5d6OYykk08Li2O2BHg=s64","userId":"02963925927313730455"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["CLASS_NAMES = np.array(['bad', 'good'])\n","CLASS_NAMES[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'bad'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"zg3l7MNuzFyL","colab_type":"code","colab":{}},"source":["#This batch size provides same size for every batch\n","#Image dimensions required for the input to Xception network\n","BATCH_SIZE = 32\n","IMG_HEIGHT = 229\n","IMG_WIDTH = 229\n","\n","#Steps for training and validation purposes\n","STEPS_PER_EPOCH = np.ceil(train_count/BATCH_SIZE)\n","STEPS_PER_EPOCH_V = np.ceil(valid_count/BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FsbnvMxv9J_0","colab_type":"code","outputId":"b76c06a2-d7d0-43ab-8d09-2194157244b4","executionInfo":{"status":"ok","timestamp":1587587428662,"user_tz":-120,"elapsed":2257,"user":{"displayName":"Michał Bernacki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnmPN0hwphGAGXExHQyanC5d6OYykk08Li2O2BHg=s64","userId":"02963925927313730455"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Train batches generator\n","train_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.xception.preprocess_input)\n","\n","train_generator = train_datagen.flow_from_directory(directory=str(train_dir),\n","                                                    batch_size=BATCH_SIZE,\n","                                                    shuffle=True,\n","                                                    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                    class_mode='binary')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 5600 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UL_iKIE4KccJ","colab_type":"code","outputId":"42e34a9b-ec31-4247-9680-1ce80144e260","executionInfo":{"status":"ok","timestamp":1587587429272,"user_tz":-120,"elapsed":2855,"user":{"displayName":"Michał Bernacki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnmPN0hwphGAGXExHQyanC5d6OYykk08Li2O2BHg=s64","userId":"02963925927313730455"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Validation batches generator\n","valid_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.xception.preprocess_input)\n","\n","valid_generator = valid_datagen.flow_from_directory(directory=str(valid_dir),\n","                                                    batch_size=BATCH_SIZE,\n","                                                    shuffle=True,\n","                                                    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                    class_mode='binary')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 800 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"frDoHnS59KAE","colab_type":"code","colab":{}},"source":["#Import Xception model with weights trained on ImageNet dataset, without last layer\n","base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n","avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n","output = keras.layers.Dense(2, activation=\"softmax\")(avg)\n","model = keras.models.Model(inputs=base_model.input, outputs=output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IjO0w3WR9KAJ","colab_type":"code","outputId":"4d23814c-9391-4ccd-e37f-2100813c9648","executionInfo":{"status":"ok","timestamp":1587587712824,"user_tz":-120,"elapsed":272537,"user":{"displayName":"Michał Bernacki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnmPN0hwphGAGXExHQyanC5d6OYykk08Li2O2BHg=s64","userId":"02963925927313730455"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#Freezing all Xception layers for first 5 epochs\n","#Unfreezed remain only avg and output layer\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","checkpoint_cb = keras.callbacks.ModelCheckpoint(\"/content/gdrive/My Drive/image_x_model_ts.h5\", save_best_only=True)\n","optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","history = model.fit(train_generator,\n","                    steps_per_epoch=STEPS_PER_EPOCH,\n","                    validation_data=valid_generator,\n","                    validation_steps=STEPS_PER_EPOCH_V,\n","                    epochs=5,\n","                    callbacks=[checkpoint_cb])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","175/175 [==============================] - 55s 312ms/step - loss: 1.6746 - accuracy: 0.7782 - val_loss: 1.1073 - val_accuracy: 0.8625\n","Epoch 2/5\n","175/175 [==============================] - 54s 308ms/step - loss: 0.9850 - accuracy: 0.8061 - val_loss: 0.6902 - val_accuracy: 0.8175\n","Epoch 3/5\n","175/175 [==============================] - 53s 302ms/step - loss: 0.6226 - accuracy: 0.8300 - val_loss: 0.7437 - val_accuracy: 0.7550\n","Epoch 4/5\n","175/175 [==============================] - 54s 309ms/step - loss: 0.4637 - accuracy: 0.8429 - val_loss: 0.6020 - val_accuracy: 0.8562\n","Epoch 5/5\n","175/175 [==============================] - 53s 300ms/step - loss: 0.3974 - accuracy: 0.8525 - val_loss: 0.6853 - val_accuracy: 0.7550\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B3bibzSxghpy","colab_type":"code","outputId":"d4002a94-9ec8-40fd-8dcd-f8c8b5b8484d","executionInfo":{"status":"ok","timestamp":1587589865924,"user_tz":-120,"elapsed":2146102,"user":{"displayName":"Michał Bernacki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnmPN0hwphGAGXExHQyanC5d6OYykk08Li2O2BHg=s64","userId":"02963925927313730455"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["#Unfreezing base model layers for next epochs\n","for layer in base_model.layers:\n","    layer.trainable = True\n","\n","checkpoint_cb = keras.callbacks.ModelCheckpoint(\"/content/gdrive/My Drive/image_x_model.h5\", save_best_only=True)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n","optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True, decay=0.001)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","history = model.fit(train_generator,\n","                    steps_per_epoch=STEPS_PER_EPOCH,\n","                    validation_data=valid_generator,\n","                    validation_steps=STEPS_PER_EPOCH_V,\n","                    epochs=100,\n","                    callbacks=[checkpoint_cb, early_stopping_cb])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","175/175 [==============================] - 151s 864ms/step - loss: 0.3171 - accuracy: 0.8691 - val_loss: 0.1708 - val_accuracy: 0.9275\n","Epoch 2/100\n","175/175 [==============================] - 144s 820ms/step - loss: 0.1370 - accuracy: 0.9379 - val_loss: 0.1052 - val_accuracy: 0.9575\n","Epoch 3/100\n","175/175 [==============================] - 143s 819ms/step - loss: 0.0688 - accuracy: 0.9704 - val_loss: 0.0581 - val_accuracy: 0.9775\n","Epoch 4/100\n","175/175 [==============================] - 141s 808ms/step - loss: 0.0473 - accuracy: 0.9780 - val_loss: 0.1028 - val_accuracy: 0.9613\n","Epoch 5/100\n","175/175 [==============================] - 143s 819ms/step - loss: 0.0415 - accuracy: 0.9816 - val_loss: 0.0524 - val_accuracy: 0.9775\n","Epoch 6/100\n","175/175 [==============================] - 141s 806ms/step - loss: 0.0330 - accuracy: 0.9862 - val_loss: 0.0875 - val_accuracy: 0.9712\n","Epoch 7/100\n","175/175 [==============================] - 139s 794ms/step - loss: 0.0269 - accuracy: 0.9868 - val_loss: 0.0910 - val_accuracy: 0.9638\n","Epoch 8/100\n","175/175 [==============================] - 140s 799ms/step - loss: 0.0248 - accuracy: 0.9896 - val_loss: 0.0683 - val_accuracy: 0.9688\n","Epoch 9/100\n","175/175 [==============================] - 142s 811ms/step - loss: 0.0247 - accuracy: 0.9879 - val_loss: 0.0822 - val_accuracy: 0.9737\n","Epoch 10/100\n","175/175 [==============================] - 140s 800ms/step - loss: 0.0184 - accuracy: 0.9911 - val_loss: 0.0823 - val_accuracy: 0.9737\n","Epoch 11/100\n","175/175 [==============================] - 141s 804ms/step - loss: 0.0175 - accuracy: 0.9912 - val_loss: 0.0806 - val_accuracy: 0.9725\n","Epoch 12/100\n","175/175 [==============================] - 141s 806ms/step - loss: 0.0162 - accuracy: 0.9918 - val_loss: 0.0788 - val_accuracy: 0.9787\n","Epoch 13/100\n","175/175 [==============================] - 140s 802ms/step - loss: 0.0154 - accuracy: 0.9918 - val_loss: 0.0870 - val_accuracy: 0.9750\n","Epoch 14/100\n","175/175 [==============================] - 140s 799ms/step - loss: 0.0136 - accuracy: 0.9932 - val_loss: 0.0795 - val_accuracy: 0.9775\n","Epoch 15/100\n","175/175 [==============================] - 142s 809ms/step - loss: 0.0118 - accuracy: 0.9941 - val_loss: 0.0901 - val_accuracy: 0.9762\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nLCtYJUvhXqN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}